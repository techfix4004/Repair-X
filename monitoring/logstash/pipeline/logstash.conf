input {
  # Filebeat input for application logs
  beats {
    port => 5044
  }
  
  # TCP input for direct log shipping
  tcp {
    port => 5000
    type => "repairx-logs"
  }
  
  # HTTP input for webhook logs
  http {
    port => 8080
    type => "repairx-webhook"
  }
}

filter {
  # Parse JSON logs
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
    }
  }
  
  # Parse RepairX application logs
  if [type] == "repairx-logs" {
    grok {
      match => { 
        "message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] %{LOGLEVEL:level}: %{GREEDYDATA:log_message}" 
      }
    }
    
    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }
  
  # Parse access logs
  if [fields][log_type] == "access" {
    grok {
      match => { 
        "message" => '%{COMBINEDAPACHELOG}' 
      }
    }
    
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }
    
    # Parse user agent
    if [agent] != "-" {
      useragent {
        source => "agent"
        target => "user_agent"
      }
    }
    
    # GeoIP enrichment
    if [clientip] {
      geoip {
        source => "clientip"
        target => "geoip"
      }
    }
  }
  
  # Parse error logs
  if [fields][log_type] == "error" {
    mutate {
      add_field => { "severity" => "error" }
    }
  }
  
  # Parse security logs
  if [fields][log_type] == "security" {
    mutate {
      add_field => { "category" => "security" }
    }
    
    # Detect failed login attempts
    if [log_message] =~ /failed.*login/i {
      mutate {
        add_field => { "security_event" => "failed_login" }
        add_field => { "severity" => "warning" }
      }
    }
    
    # Detect suspicious activities
    if [log_message] =~ /suspicious|attack|intrusion/i {
      mutate {
        add_field => { "security_event" => "suspicious_activity" }
        add_field => { "severity" => "critical" }
      }
    }
  }
  
  # Parse business logs
  if [fields][log_type] == "business" {
    mutate {
      add_field => { "category" => "business" }
    }
    
    # Parse revenue events
    if [log_message] =~ /payment.*completed/i {
      mutate {
        add_field => { "business_event" => "payment_completed" }
      }
      
      # Extract amount if present
      grok {
        match => { 
          "log_message" => "amount[:\s]*\$?(?<payment_amount>\d+\.?\d*)" 
        }
        tag_on_failure => ["_grokparsefailure_amount"]
      }
    }
    
    # Parse job completion events
    if [log_message] =~ /job.*completed/i {
      mutate {
        add_field => { "business_event" => "job_completed" }
      }
    }
  }
  
  # Add environment information
  mutate {
    add_field => {
      "environment" => "${ENVIRONMENT:development}"
      "service" => "repairx"
    }
  }
  
  # Remove unnecessary fields
  mutate {
    remove_field => [ "agent", "ecs", "input", "host" ]
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "repairx-logs-%{+YYYY.MM.dd}"
    template_name => "repairx"
    template => "/usr/share/logstash/config/elasticsearch-template.json"
    template_overwrite => true
  }
  
  # Debug output (remove in production)
  if [@metadata][debug] {
    stdout {
      codec => rubydebug
    }
  }
  
  # Send critical errors to AlertManager via webhook
  if [severity] == "critical" {
    http {
      url => "http://alertmanager:9093/api/v1/alerts"
      http_method => "post"
      format => "json"
      mapping => {
        "alerts" => [{
          "labels" => {
            "alertname" => "CriticalLogEvent"
            "severity" => "%{severity}"
            "service" => "%{service}"
            "environment" => "%{environment}"
          }
          "annotations" => {
            "summary" => "Critical log event detected"
            "description" => "%{log_message}"
          }
        }]
      }
    }
  }
}